<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link 
        rel="stylesheet" 
        href="static/styles/app.css"
    />
    <title>Lip Sync TTS</title>
</head>
<body style="display: flex; flex-direction: column;">
    <div id="content-section">
        <h1 id="title-h1" style="text-align: center;">MYWAIFU.CHAT alpha v-- </h1>
        <div id="horizontal-section">
            <div id="vertical-section">
                
            </div>
            <div id="chat-log-container">
                <div id="chat-log">
                    
                    {% for message in messages %}
                        {% if message.role == "user" %}
                            <p class="user-message">{{ message.content }}</p>
                        {% else %}
                            <p class="ai-message">{{ message.content }}</p>
                        {% endif %}
                    {% endfor %}
                </div>
                <canvas id="lipCanvas" width="500" height="500"></canvas>
                <form action="/" method="post">
                    <input type="text" name="text" placeholder="Type your message here..."></input>
                    <button id="send-button" type="submit">Send</button>
                    <button id="record-button" type="button">
                        <!--Microphone from local path static/icons/mic.svg-->
                        <svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24"><path d="M480-400q-50 0-85-35t-35-85v-240q0-50 35-85t85-35q50 0 85 35t35 85v240q0 50-35 85t-85 35Zm0-240Zm-40 520v-123q-104-14-172-93t-68-184h80q0 83 58.5 141.5T480-320q83 0 141.5-58.5T680-520h80q0 105-68 184t-172 93v123h-80Zm40-360q17 0 28.5-11.5T520-520v-240q0-17-11.5-28.5T480-800q-17 0-28.5 11.5T440-760v240q0 17 11.5 28.5T480-480Z"/></svg>
                    </button>

                </form>
            </div>
        </div>
    </div>

    {% if request.method == 'POST' %}
        <audio src="{{ audio_file }}"></audio>
        <div id="imgs" style="display: none;">
            {% for shape in mouth_shapes %}
                <img src="{{ shape }}" alt="mouth shape" width="50" height="50" />
            {% endfor %}
        </div>
        <div id="comb" style="display: none;">
            {% for com in combined %}
                <p>{{ com }}</p>
            {% endfor %}
        </div>
    {% endif %}


    <script>
        var canvas = document.getElementById("lipCanvas");
        var ctx = canvas.getContext("2d");
        var audio = document.getElementsByTagName("audio")[0];
        /*when the user clicks on the record button, record the audio until the user clicks it again, then send the audio to the server along with anything else*/
        var recording = false;
        document.getElementById("record-button").addEventListener("click", function() {
            if(recording) {
                //stop recording
                recording = false;
                document.getElementById("record-button").innerHTML = "Sending...";
                audio.pause();
            } else {
                //start recording
                recording = true;
                document.getElementById("record-button").innerHTML = "Stop Recording";
                navigator.mediaDevices.getUserMedia({audio: true})
                .then(stream => {
                    const mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.start();
                    const audioChunks = [];
                    mediaRecorder.addEventListener("dataavailable", event => {
                        audioChunks.push(event.data);
                    });
                    mediaRecorder.addEventListener("stop", () => {
                        const audioBlob = new Blob(audioChunks);
                        const audioUrl = URL.createObjectURL(audioBlob);
                        const audio = new Audio(audioUrl);
                        //convert to bytes-like object or ascii string
                        let reader = new FileReader();
                        reader.readAsDataURL(audioBlob);
                        reader.onloadend = function() {
                            let base64data = reader.result;
                            //send get request to audio_to_text with the audio data to get text. log the text
                            let xhr = new XMLHttpRequest();
                            xhr.open("POST", "/audio_to_text", true);
                            xhr.setRequestHeader("Content-Type", "application/json");
                            xhr.send(JSON.stringify({audio: base64data}));
                            //when the response is received, log it. Response just contains the text object
                            xhr.onload = function() {
                                let response = JSON.parse(xhr.responseText);
                                let text = response.text;
                                console.log(text);
                                //set input text to the text and submit
                                document.getElementsByTagName("input")[0].value = text;
                                document.getElementsByTagName("form")[0].submit();

                            }

                        }

                    });
                    setTimeout(() => {
                        mediaRecorder.stop();
                    }, 5000);
                });
            }
        });
        //set default img
        let defaultImg = new Image();
        defaultImg.src = "static/lip_shapes/TS.png";
        defaultImg.onload = function() {
                        
            // step 1
            const oc = document.createElement('canvas');
            const octx = oc.getContext('2d');
            oc.width = this.width;
            oc.height = this.height;

            // step 2: pre-filter image using steps as radius
            const steps = (oc.width / canvas.width)>>1;
            octx.filter = `blur(${steps}px)`;
            octx.drawImage(this, 0, 0);

            // step 3, draw scaled
            ctx.drawImage(oc, 0, 0, oc.width, oc.height, 0, 0, canvas.width, canvas.height);
        }
        //on send-button click, animate a loading symbol in place of the button text
        document.getElementById("send-button").addEventListener("click", function() {
            let button = document.getElementById("send-button");
            button.innerHTML = `<img src="static/imgs/loading.gif" alt="loading" width="20" height="20" />`;
        }); 
        audio.addEventListener('loadedmetadata', function() {
            var audioLength = Math.abs(audio.duration);
            var numSections = document.getElementById("imgs").childElementCount;

            let combined = document.getElementById("comb").children;
            combined = Array.from(combined).map(function(item) {
                let inner = item.innerHTML;
                inner = inner.replace("(", "").replace(")", "");
                let [imgPath, start] = inner.split(",");
                imgPath = imgPath.replace(/'/g, "").trim();
                start = parseFloat(start.trim());
                return {imgPath: imgPath, start: start};
            });
            setTimeout(function() {
                audio.play();
            }, 10);
            for(let i = 0; i < combined.length; i++) {
                let imgPath = combined[i].imgPath;
                let start = combined[i].start;
                if(start < 0) start = 0;
                let image = new Image();
                image.src = imgPath;
                image.onload = function() {
                    setTimeout(() =>{
                        // step 1
                        const oc = document.createElement('canvas');
                        const octx = oc.getContext('2d');
                        oc.width = this.width;
                        oc.height = this.height;

                        // step 2: pre-filter image using steps as radius
                        const steps = (oc.width / canvas.width)>>1;
                        octx.filter = `blur(${steps}px)`;
                        octx.drawImage(this, 0, 0);

                        // step 3, draw scaled
                        ctx.drawImage(oc, 0, 0, oc.width, oc.height, 0, 0, canvas.width, canvas.height);

                    }, start * 1000);
                };
            }

            if(audioLength < 0) audioLength = 0;
            setTimeout(function() {
                let defaultImg = new Image();
                defaultImg.src = "static/lip_shapes/TS.png";
                defaultImg.onload = function() {
                    
                    // step 1
                    const oc = document.createElement('canvas');
                    const octx = oc.getContext('2d');
                    oc.width = this.width;
                    oc.height = this.height;

                    // step 2: pre-filter image using steps as radius
                    const steps = (oc.width / canvas.width)>>1;
                    octx.filter = `blur(${steps}px)`;
                    octx.drawImage(this, 0, 0);

                    // step 3, draw scaled
                    ctx.drawImage(oc, 0, 0, oc.width, oc.height, 0, 0, canvas.width, canvas.height);
                }
                //send post request to audio_finished to indicate that the audio has finished playing. Specify which file in the request body
                //get audio by getting src of audio el
                let audioSrc = document.getElementsByTagName("audio")[0].src;
                let audioFile = audioSrc.split("/").pop();
                let xhr = new XMLHttpRequest();
                xhr.open("POST", "/audio_finished", true);
                xhr.setRequestHeader("Content-Type", "application/json");
                xhr.send(JSON.stringify({audio_file: "static/"+audioFile}));
                
            }, audioLength * 1000);
        });
    </script>
</body>
</html>
